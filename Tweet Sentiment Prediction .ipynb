{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "''' Natural Language Processing is wide field as we know before,Here we are discussing about basic applications of NLP That is Sentiment Analysis on Twitter data which is popular evry one.\n",
    "we will take up an extremely popular use case of NLP - building a supervised machine learning model on text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probelem Statement \n",
    "\n",
    " The problem in sentiment analysis is classifyingthe polarity of a given text at the document,sentence, or feature/aspect level \n",
    " \n",
    " ● To predict whether the expressed opinion in a document, asentence or an entity feature/aspect is positive,negative, or   \n",
    "   neutral .\n",
    " \n",
    " ● To implement an algorithm for automaticclassification of text into positive, negative or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "- tweet.csv\n",
    "\n",
    "Here we are taking a open data that have collection of tweets and that is the only column we have.\n",
    "Our dataset size is around (31962, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessory libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string \n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet\n",
       "0   1   @user when a father is dysfunctional and is s...\n",
       "1   2  @user @user thanks for #lyft credit i can't us...\n",
       "2   3                                bihday your majesty\n",
       "3   4  #model   i love u take with u all the time in ...\n",
       "4   5             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ca see our data include so many Non-ASCII characters and other special charecters so we have to get ride all of that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying function to remove Non-ASCII characters \n",
    " -  with \"string.printable\" function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(lambda y: ''.join(filter(lambda x: \n",
    "            x in string.printable, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet\n",
       "0   1   @user when a father is dysfunctional and is s...\n",
       "1   2  @user @user thanks for #lyft credit i can't us...\n",
       "2   3                                bihday your majesty\n",
       "3   4  #model   i love u take with u all the time in ...\n",
       "4   5             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def clean_tweet(tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\" (@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet).split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>user thanks for lyft credit i can t use cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet\n",
       "0   1  when a father is dysfunctional and is so selfi...\n",
       "1   2  user thanks for lyft credit i can t use cause ...\n",
       "2   3                                bihday your majesty\n",
       "3   4      model i love u take with u all the time in ur\n",
       "4   5                  factsguide society now motivation"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data look more sexy than before we can go for further steps with this data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    " Here we will calculate polarity of each sentence and based on the polarity give them the labels wheather its Positive,Negative or Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(tweet) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Labels']=df['tweet'].apply(get_tweet_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>user thanks for lyft credit i can t use cause ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet    Labels\n",
       "0   1  when a father is dysfunctional and is so selfi...  negative\n",
       "1   2  user thanks for lyft credit i can t use cause ...  positive\n",
       "2   3                                bihday your majesty   neutral\n",
       "3   4      model i love u take with u all the time in ur  positive\n",
       "4   5                  factsguide society now motivation   neutral"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the occurance of sentiment\n",
    "\n",
    " Let us check the distribution of the target class which can be done using barplot.groups the 'Labels' variables by counting the number of their occurrences. It is evident that we have more occurrences of 'Positive' than 'Negative and Neutral' in the target variable. Still, the good thing is that the difference is not significant and the data is relatively balanced.\n",
    "\n",
    "The baseline accuracy is important but often ignored in machine learning. It sets the benchmark in terms of minimum accuracy which the model should achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6257430698955009\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Labels').tweet.count().plot.bar(ylim=0)\n",
    "plt.show()\n",
    "print(20000/31962) #Baseline accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline accuracy is 62.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data with NLTK\n",
    " \n",
    " Here we will do some additional data cleaning using NLTK to get good data for our classification problem.\n",
    " Here we used Stemmming , Stop word removing and regular expression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>user thanks for lyft credit i can t use cause ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet    Labels\n",
       "0   1  when a father is dysfunctional and is so selfi...  negative\n",
       "1   2  user thanks for lyft credit i can t use cause ...  positive\n",
       "2   3                                bihday your majesty   neutral\n",
       "3   4      model i love u take with u all the time in ur  positive\n",
       "4   5                  factsguide society now motivation   neutral"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweets'] = df['tweet'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\n",
    "                                                         split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['tweet'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>user thank lyft credit use caus offer wheelcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bihday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>factsguid societi motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    Labels                                             Tweets\n",
       "0   1  negative      father dysfunct selfish drag kid dysfunct run\n",
       "1   2  positive  user thank lyft credit use caus offer wheelcha...\n",
       "2   3   neutral                                     bihday majesti\n",
       "3   4  positive                        model love u take u time ur\n",
       "4   5   neutral                            factsguid societi motiv"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is well cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ML model to get a prediction on our train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitig the data \n",
    "\n",
    "We have already imported necessory pakages to split our data into train and test.\n",
    "\n",
    "we are creating an array of the target variable, called 'target'.\n",
    "\n",
    "\n",
    "Then we are creating the training (X_train, y_train) and test set (X-test, y_test) arrays. It keeps 30% of the data for testing the model. The 'random_state' argument ensures that the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 3)\n",
      "(22373,)\n",
      "(9589,)\n"
     ]
    }
   ],
   "source": [
    "target = df['Labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweets'], target, test_size=0.30, random_state=100)\n",
    "\n",
    "print(df.shape); print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Text to Word Frequency Vectors with Tf-Idf Vectorizer.\n",
    "\n",
    " We have processed the text, but we need to convert it to word frequency vectors for building machine learning models. There are several ways to do this, such as using CountVectorizer and HashingVectorizer, but the TfidfVectorizer is the most popular one.\n",
    "\n",
    "TF-IDF is an acronym that stands for 'Term Frequency-Inverse Document Frequency'. It is used as a weighting factor in text mining applications.\n",
    "\n",
    "\n",
    "Term Frequency (TF): This summarizes the normalized Term Frequency within a document.\n",
    "\n",
    "\n",
    "Inverse Document Frequency (IDF): This reduces the weight of terms that appear a lot across documents. In simple terms, TF-IDF attempts to highlight important words which are frequent in a document but not across documents. We will work on creating TF-IDF vectors for our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aaaaa', 'aaaaaand', 'aaaaah', 'aaahh', 'aaand', 'aaawwwww', 'aaberg', 'aah']\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))\n",
    "\n",
    "print(vectorizer_tfidf.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22373, 24946)\n",
      "(9589, 24946)\n"
     ]
    }
   ],
   "source": [
    "print(train_tfIdf.shape); print(test_tfIdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit the Classifier.\n",
    "Now, we will build the text classification model. Here i'll try 4 types of text classification models \n",
    "\n",
    "\n",
    "- Naive Bayes classifier\n",
    "- Random Forest Classifier\n",
    "- support vector machines(SVM)\n",
    "- Logistic regression\n",
    "\n",
    "And we will see which model will give us the best prediction accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_classifier.fit(train_tfIdf, y_train)\n",
    "\n",
    "pred2 = nb_classifier.predict(test_tfIdf) \n",
    "print(pred2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429241839607884\n",
      "[[4709  120    3]\n",
      " [2157 1228    6]\n",
      " [ 970  168  228]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score: score\n",
    "accuracy_tfidf = metrics.accuracy_score(y_test, pred2)\n",
    "print(accuracy_tfidf)\n",
    "\n",
    "Conf_metrics_tfidf = metrics.confusion_matrix(y_test, pred2, labels=['positive', 'neutral' , 'negative'])\n",
    "print(Conf_metrics_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 64.3% in naive_bayes classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=50, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 50)\n",
    "\n",
    "classifier.fit(train_tfIdf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'positive' 'positive' 'negative' 'positive' 'neutral'\n",
      " 'positive' 'positive' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "predRF = classifier.predict(test_tfIdf) \n",
    "print(predRF[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590051100219\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy_RF = metrics.accuracy_score(y_test, predRF)\n",
    "print(accuracy_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4216  489  127]\n",
      " [ 177 3153   61]\n",
      " [ 210  288  868]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Conf_metrics_RF = metrics.confusion_matrix(y_test, predRF, labels=['positive', 'neutral', 'negative'])\n",
    "print(Conf_metrics_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM( support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_tfIdf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'positive', ..., 'neutral', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(test_tfIdf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8721451663364271\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy_RF = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jonit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with data\n",
    "logreg.fit(train_tfIdf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predi=logreg.predict(test_tfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'positive', ..., 'neutral', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507665032850141\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy_RF = metrics.accuracy_score(y_test, y_predi)\n",
    "print(accuracy_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you have learned the fundamentals of text cleaning and pre-processing, and building and evaluating text classification models using Naive Bayes, Random Forest,Logistic reggression and SVM Algorithms. The performance of the models is summarized below:\n",
    "\n",
    "Base line accuracy = 52.5%\n",
    "\n",
    "Accuracy achieved by Naive Bayes Classifier = 54.3%\n",
    " \n",
    "Accuracy achieved by Random Forest Classifier = 86%\n",
    "\n",
    "Accuracy achieved by SVM( support vector machine) = 87.2\n",
    "\n",
    "Accuracy achieved by LogisticRegression = 85.07%\n",
    "\n",
    "As we know our problem statement was to predict whether the expressed opinion in a document, asentence or an entity feature/aspect is positive,negative, or neutral. I have tried four types of ML classificatio models So i can see  that our SVM model is giving more accurate prediction on our tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
